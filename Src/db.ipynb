{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instal libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import polars as pl\n",
    "import json\n",
    "from psycopg2 import OperationalError, sql\n",
    "from contextlib import contextmanager\n",
    "#from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME=\"testdb\"\n",
    "DB_USER=\"admin\"\n",
    "DB_PASSWORD=\"your_password\"\n",
    "DB_HOST=\"localhost\"\n",
    "DB_PORT=\"6432\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def get_db_connection():\n",
    "    \"\"\"Context manager for PostgreSQL database connection.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # Establish the connection using environment variables\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT\n",
    "        )\n",
    "        # Yield the connection to be used in the 'with' block\n",
    "        yield conn\n",
    "    except OperationalError as e:\n",
    "        print(f\"An error occurred while connecting to the database: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_db_connection():\n",
    "    \"\"\"Test function to verify database connection.\"\"\"\n",
    "    try:\n",
    "        with get_db_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Execute a simple query to test the connection\n",
    "                cur.execute(sql.SQL(\"SELECT 1\"))\n",
    "                result = cur.fetchone()\n",
    "                if result:\n",
    "                    print(\"Database connection successful.\")\n",
    "                else:\n",
    "                    print(\"Failed to retrieve data from the database.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(parquet_file_path: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and process the Parquet data file, expanding the `full_vehicleInfo` column.\n",
    "    \"\"\"\n",
    "    # Read the Parquet file\n",
    "    df = pl.read_parquet(parquet_file_path)\n",
    "\n",
    "    # Cast 'full_vehicleInfo' to Struct type and unnest\n",
    "    return df.with_columns(\n",
    "        pl.col(\"full_vehicleInfo\").cast(pl.Struct)\n",
    "    ).unnest(\"full_vehicleInfo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_into_db(df: pl.DataFrame, table_name: str):\n",
    "    \"\"\"\n",
    "    Insert data from a Polars DataFrame into a PostgreSQL table.\n",
    "    \"\"\"\n",
    "    # Convert Polars DataFrame to list of tuples\n",
    "    records = df.to_dicts()\n",
    "    \n",
    "    # Use the first record to generate column names dynamically\n",
    "    columns = list(records[0].keys())\n",
    "    rows = [tuple(record.values()) for record in records]\n",
    "\n",
    "    # Database connection\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT\n",
    "        )\n",
    "        with conn.cursor() as cur:\n",
    "            # Create an insert query dynamically\n",
    "            insert_query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES %s\"\n",
    "            execute_values(cur, insert_query, rows)\n",
    "            conn.commit()\n",
    "            print(f\"{len(rows)} records successfully inserted into {table_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while inserting data: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_polars_to_postgres_types(polars_dtype):\n",
    "    \"\"\"\n",
    "    Map Polars data types to PostgreSQL data types.\n",
    "    \"\"\"\n",
    "    type_mapping = {\n",
    "        pl.Int32: \"INTEGER\",\n",
    "        pl.Int64: \"BIGINT\",\n",
    "        pl.Float32: \"REAL\",\n",
    "        pl.Float64: \"DOUBLE PRECISION\",\n",
    "        pl.Utf8: \"TEXT\",\n",
    "        pl.Boolean: \"BOOLEAN\",\n",
    "        pl.Date: \"DATE\",\n",
    "        pl.Datetime: \"TIMESTAMP\",\n",
    "        pl.List: \"JSONB\",  # If lists are used, JSONB is a good fit\n",
    "    }\n",
    "    return type_mapping.get(polars_dtype, \"TEXT\")  # Default to TEXT for unknown types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_from_df(table_name: str, df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Create a PostgreSQL table based on the schema of a Polars DataFrame.\n",
    "    \"\"\"\n",
    "    # Generate column definitions based on DataFrame schema\n",
    "    columns = [\n",
    "        f\"{col_name} {map_polars_to_postgres_types(dtype)}\"\n",
    "        for col_name, dtype in zip(df.columns, df.dtypes)\n",
    "    ]\n",
    "    columns_sql = \", \".join(columns)\n",
    "    \n",
    "    # Construct CREATE TABLE statement\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        {columns_sql}\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    # Connect to PostgreSQL and execute the query\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT\n",
    "        )\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(create_table_query)\n",
    "            conn.commit()\n",
    "            print(f\"Table '{table_name}' created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating the table: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n"
     ]
    }
   ],
   "source": [
    "test_db_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = \"../Data/Transform/Small/data.parquet\"\n",
    "table_name = \"vehicles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_prepare_data(parquet_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'vehicles' created successfully.\n"
     ]
    }
   ],
   "source": [
    "create_table_from_df(table_name, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 records successfully inserted into vehicles.\n"
     ]
    }
   ],
   "source": [
    "insert_data_into_db(df, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
